<!doctype html><html itemscope itemtype=http://schema.org/WebPage lang=en class=no-js><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><link rel="shortcut icon" href=/favicons/favicon.ico><link rel=apple-touch-icon href=/favicons/apple-touch-icon-180x180.png sizes=180x180><link rel=icon type=image/png href=/favicons/favicon-16x16.png sizes=16x16><link rel=icon type=image/png href=/favicons/favicon-32x32.png sizes=32x32><link rel=icon type=image/png href=/favicons/android-36x36.png sizes=36x36><link rel=icon type=image/png href=/favicons/android-48x48.png sizes=48x48><link rel=icon type=image/png href=/favicons/android-72x72.png sizes=72x72><link rel=icon type=image/png href=/favicons/android-96x96.png sizes=96x96><link rel=icon type=image/png href=/favicons/android-144x144.png sizes=144x144><link rel=icon type=image/png href=/favicons/android-192x192.png sizes=192x192><title>Processor API | </title><meta name=description content="Processor API The Processor API allows developers to define and connect custom processors and to interact with state stores. With the Processor API, you can define arbitrary stream processors that process one received record at a time, and connect these processors with their associated state stores to compose the processor topology that represents a customized processing logic.
Table of Contents
Overview Defining a Stream Processor Unit Testing Processors State Stores Defining and creating a State Store Fault-tolerant State Stores Enable or Disable Fault Tolerance of State Stores (Store Changelogs) Timestamped State Stores Versioned Key-Value State Stores Implementing Custom State Stores Connecting Processors and State Stores Accessing Processor Context Overview The Processor API can be used to implement both stateless as well as stateful operations, where the latter is achieved through the use of state stores."><meta property="og:title" content="Processor API"><meta property="og:description" content="Processor API The Processor API allows developers to define and connect custom processors and to interact with state stores. With the Processor API, you can define arbitrary stream processors that process one received record at a time, and connect these processors with their associated state stores to compose the processor topology that represents a customized processing logic.
Table of Contents
Overview Defining a Stream Processor Unit Testing Processors State Stores Defining and creating a State Store Fault-tolerant State Stores Enable or Disable Fault Tolerance of State Stores (Store Changelogs) Timestamped State Stores Versioned Key-Value State Stores Implementing Custom State Stores Connecting Processors and State Stores Accessing Processor Context Overview The Processor API can be used to implement both stateless as well as stateful operations, where the latter is achieved through the use of state stores."><meta property="og:type" content="article"><meta property="og:url" content="https://example.kafka-site-md.dev/36/streams/developer-guide/processor-api/"><meta property="article:section" content="36"><meta property="article:modified_time" content="2025-01-03T19:54:29-08:00"><meta itemprop=name content="Processor API"><meta itemprop=description content="Processor API The Processor API allows developers to define and connect custom processors and to interact with state stores. With the Processor API, you can define arbitrary stream processors that process one received record at a time, and connect these processors with their associated state stores to compose the processor topology that represents a customized processing logic.
Table of Contents
Overview Defining a Stream Processor Unit Testing Processors State Stores Defining and creating a State Store Fault-tolerant State Stores Enable or Disable Fault Tolerance of State Stores (Store Changelogs) Timestamped State Stores Versioned Key-Value State Stores Implementing Custom State Stores Connecting Processors and State Stores Accessing Processor Context Overview The Processor API can be used to implement both stateless as well as stateful operations, where the latter is achieved through the use of state stores."><meta itemprop=dateModified content="2025-01-03T19:54:29-08:00"><meta itemprop=wordCount content="3847"><meta itemprop=keywords content="kafka,docs,"><meta name=twitter:card content="summary"><meta name=twitter:title content="Processor API"><meta name=twitter:description content="Processor API The Processor API allows developers to define and connect custom processors and to interact with state stores. With the Processor API, you can define arbitrary stream processors that process one received record at a time, and connect these processors with their associated state stores to compose the processor topology that represents a customized processing logic.
Table of Contents
Overview Defining a Stream Processor Unit Testing Processors State Stores Defining and creating a State Store Fault-tolerant State Stores Enable or Disable Fault Tolerance of State Stores (Store Changelogs) Timestamped State Stores Versioned Key-Value State Stores Implementing Custom State Stores Connecting Processors and State Stores Accessing Processor Context Overview The Processor API can be used to implement both stateless as well as stateful operations, where the latter is achieved through the use of state stores."><link rel=preload href=/scss/main.min.7ed0eb3fc68a0678ca492e0db9c00f8e8d5b776bbb2fb833732191f6bbf02877.css as=style integrity="sha256-ftDrP8aKBnjKSS4NucAPjo1bd2u7L7gzcyGR9rvwKHc=" crossorigin=anonymous><link href=/scss/main.min.7ed0eb3fc68a0678ca492e0db9c00f8e8d5b776bbb2fb833732191f6bbf02877.css rel=stylesheet integrity="sha256-ftDrP8aKBnjKSS4NucAPjo1bd2u7L7gzcyGR9rvwKHc=" crossorigin=anonymous><script src=https://code.jquery.com/jquery-3.7.1.min.js integrity="sha512-v2CJ7UaYy4JwqLDIrZUI/4hqeoQieOmAZNXBeQyjo21dadnwR+8ZaIJVT8EE2iyI61OV8e6M8PP2/4hpQINQ/g==" crossorigin=anonymous></script><script defer src=https://unpkg.com/lunr@2.3.9/lunr.min.js integrity=sha384-203J0SNzyqHby3iU6hzvzltrWi/M41wOP5Gu+BiJMz5nwKykbkUx8Kp7iti0Lpli crossorigin=anonymous></script></head><body class=td-page><header><nav class="td-navbar js-navbar-scroll" data-bs-theme=dark><div class="container-fluid flex-column flex-md-row"><a class=navbar-brand href=/><span class="navbar-brand__logo navbar-logo"><svg width="154" height="250" viewBox="0 0 256 416" xmlns="http://www.w3.org/2000/svg" preserveAspectRatio="xMidYMid"><path d="M201.816 230.216c-16.186.0-30.697 7.171-40.634 18.461l-25.463-18.026c2.703-7.442 4.255-15.433 4.255-23.797.0-8.219-1.498-16.076-4.112-23.408l25.406-17.835c9.936 11.233 24.409 18.365 40.548 18.365 29.875.0 54.184-24.305 54.184-54.184.0-29.879-24.309-54.184-54.184-54.184s-54.184 24.305-54.184 54.184c0 5.348.808 10.505 2.258 15.389l-25.423 17.844c-10.62-13.175-25.911-22.374-43.333-25.182v-30.64c24.544-5.155 43.037-26.962 43.037-53.019C124.171 24.305 99.862.0 69.987.0 40.112.0 15.803 24.305 15.803 54.184c0 25.708 18.014 47.246 42.067 52.769v31.038C25.044 143.753.0 172.401.0 206.854c0 34.621 25.292 63.374 58.355 68.94v32.774c-24.299 5.341-42.552 27.011-42.552 52.894.0 29.879 24.309 54.184 54.184 54.184s54.184-24.305 54.184-54.184c0-25.883-18.253-47.553-42.552-52.894v-32.775a69.965 69.965.0 0042.6-24.776l25.633 18.143c-1.423 4.84-2.22 9.946-2.22 15.24.0 29.879 24.309 54.184 54.184 54.184S256 314.279 256 284.4c0-29.879-24.309-54.184-54.184-54.184zm0-126.695c14.487.0 26.27 11.788 26.27 26.271s-11.783 26.27-26.27 26.27-26.27-11.787-26.27-26.27 11.783-26.271 26.27-26.271zm-158.1-49.337c0-14.483 11.784-26.27 26.271-26.27s26.27 11.787 26.27 26.27c0 14.483-11.783 26.27-26.27 26.27s-26.271-11.787-26.271-26.27zm52.541 307.278c0 14.483-11.783 26.27-26.27 26.27s-26.271-11.787-26.271-26.27 11.784-26.27 26.271-26.27 26.27 11.787 26.27 26.27zm-26.272-117.97c-20.205.0-36.642-16.434-36.642-36.638.0-20.205 16.437-36.642 36.642-36.642 20.204.0 36.641 16.437 36.641 36.642.0 20.204-16.437 36.638-36.641 36.638zm131.831 67.179c-14.487.0-26.27-11.788-26.27-26.271s11.783-26.27 26.27-26.27 26.27 11.787 26.27 26.27-11.783 26.271-26.27 26.271z" style="fill:#231f20"/></svg></span><span class=navbar-brand__name></span></a><div class="td-navbar-nav-scroll ms-md-auto" id=main_navbar><ul class=navbar-nav><li class=nav-item><a class=nav-link href=/41/><span>Documentation</span></a></li><li class=nav-item><a class=nav-link href=/blog/><span>Blog</span></a></li><li class=nav-item><a class=nav-link href=/community/><span>Community</span></a></li><li class=nav-item><a class=nav-link href=/testimonials/><span>Testimonials</span></a></li><li class=nav-item><a class=nav-link href=/community/downloads/><span>Download Kafka</span></a></li><li class="nav-item dropdown d-none d-lg-block"><div class=dropdown><a class="nav-link dropdown-toggle" href=# role=button data-bs-toggle=dropdown aria-haspopup=true aria-expanded=false>Releases</a><ul class=dropdown-menu><li><a class=dropdown-item href=/41/>4.1</a></li><li><a class=dropdown-item href=/40/>4.0</a></li><li><a class=dropdown-item href=/39/>3.9</a></li><li><a class=dropdown-item href=/38/>3.8</a></li><li><a class=dropdown-item href=/37/>3.7</a></li><li><a class=dropdown-item href=/36/>3.6</a></li><li><a class=dropdown-item href=/35/>3.5</a></li><li><a class=dropdown-item href=/34/>3.4</a></li><li><a class=dropdown-item href=/33/>3.3</a></li><li><a class=dropdown-item href=/32/>3.2</a></li><li><a class=dropdown-item href=/31/>3.1</a></li><li><a class=dropdown-item href=/30/>3.0</a></li><li><a class=dropdown-item href=/28/>2.8</a></li><li><a class=dropdown-item href=/27/>2.7</a></li><li><a class=dropdown-item href=/26/>2.6</a></li><li><a class=dropdown-item href=/25/>2.5</a></li><li><a class=dropdown-item href=/24/>2.4</a></li><li><a class=dropdown-item href=/23/>2.3</a></li><li><a class=dropdown-item href=/22/>2.2</a></li><li><a class=dropdown-item href=/21/>2.1</a></li><li><a class=dropdown-item href=/20/>2.0</a></li><li><a class=dropdown-item href=/11/>1.1</a></li><li><a class=dropdown-item href=/10/>1.0</a></li><li><a class=dropdown-item href=/0110/>0.11.0</a></li><li><a class=dropdown-item href=/0102/>0.10.2</a></li><li><a class=dropdown-item href=/0101/>0.10.1</a></li><li><a class=dropdown-item href=/0100/>0.10.0</a></li><li><a class=dropdown-item href=/090/>0.9.0</a></li><li><a class=dropdown-item href=/082/>0.8.2</a></li><li><a class=dropdown-item href=/081/>0.8.1</a></li><li><a class=dropdown-item href=/080/>0.8.0</a></li><li><a class=dropdown-item href=/07/>0.7</a></li></ul></div></li></ul></div><div class="d-none d-lg-block"><div class="td-search td-search--offline"><div class=td-search__icon></div><input type=search class="td-search__input form-control" placeholder="Search this site…" aria-label="Search this site…" autocomplete=off data-offline-search-index-json-src=/offline-search-index.e58a36913f949563db0a14b5eaf8f6a5.json data-offline-search-base-href=/ data-offline-search-max-results=10></div></div></div></nav></header><div class="container-fluid td-outer"><div class=td-main><div class="row flex-xl-nowrap"><aside class="col-12 col-md-3 col-xl-2 td-sidebar d-print-none"><div id=td-sidebar-menu class=td-sidebar__inner><div id=content-mobile><form class="td-sidebar__search d-flex align-items-center"><div class="td-search td-search--offline"><div class=td-search__icon></div><input type=search class="td-search__input form-control" placeholder="Search this site…" aria-label="Search this site…" autocomplete=off data-offline-search-index-json-src=/offline-search-index.e58a36913f949563db0a14b5eaf8f6a5.json data-offline-search-base-href=/ data-offline-search-max-results=10></div><button class="btn btn-link td-sidebar__toggle d-md-none p-0 ms-3 fas fa-bars" type=button data-bs-toggle=collapse data-bs-target=#td-section-nav aria-controls=td-section-nav aria-expanded=false aria-label="Toggle section navigation"></button></form></div><div id=content-desktop></div><nav class="td-sidebar-nav collapse td-sidebar-nav--search-disabled foldable-nav" id=td-section-nav><ul class="td-sidebar-nav__section pe-md-3 ul-0"><li class="td-sidebar-nav__section-title td-sidebar-nav__section with-child active-path" id=m-36-li><a href=/36/ class="align-left ps-0 td-sidebar-link td-sidebar-link__section tree-root" id=m-36><span>AK 3.6.X</span></a><ul class=ul-1><li class="td-sidebar-nav__section-title td-sidebar-nav__section with-child" id=m-36getting-started-li><input type=checkbox id=m-36getting-started-check>
<label for=m-36getting-started-check><a href=/36/getting-started/ class="align-left ps-0 td-sidebar-link td-sidebar-link__section" id=m-36getting-started><span>Getting Started</span></a></label><ul class="ul-2 foldable"><li class="td-sidebar-nav__section-title td-sidebar-nav__section without-child" id=m-36getting-startedintroduction-li><input type=checkbox id=m-36getting-startedintroduction-check>
<label for=m-36getting-startedintroduction-check><a href=/36/getting-started/introduction/ class="align-left ps-0 td-sidebar-link td-sidebar-link__page" id=m-36getting-startedintroduction><span>Introduction</span></a></label></li><li class="td-sidebar-nav__section-title td-sidebar-nav__section without-child" id=m-36getting-starteduses-li><input type=checkbox id=m-36getting-starteduses-check>
<label for=m-36getting-starteduses-check><a href=/36/getting-started/uses/ class="align-left ps-0 td-sidebar-link td-sidebar-link__page" id=m-36getting-starteduses><span>Use Cases</span></a></label></li><li class="td-sidebar-nav__section-title td-sidebar-nav__section without-child" id=m-36getting-startedquickstart-li><input type=checkbox id=m-36getting-startedquickstart-check>
<label for=m-36getting-startedquickstart-check><a href=/36/getting-started/quickstart/ class="align-left ps-0 td-sidebar-link td-sidebar-link__page" id=m-36getting-startedquickstart><span>Quick Start</span></a></label></li><li class="td-sidebar-nav__section-title td-sidebar-nav__section without-child" id=m-36getting-startedecosystem-li><input type=checkbox id=m-36getting-startedecosystem-check>
<label for=m-36getting-startedecosystem-check><a href=/36/getting-started/ecosystem/ class="align-left ps-0 td-sidebar-link td-sidebar-link__page" id=m-36getting-startedecosystem><span>Ecosystem</span></a></label></li><li class="td-sidebar-nav__section-title td-sidebar-nav__section without-child" id=m-36getting-startedupgrade-li><input type=checkbox id=m-36getting-startedupgrade-check>
<label for=m-36getting-startedupgrade-check><a href=/36/getting-started/upgrade/ class="align-left ps-0 td-sidebar-link td-sidebar-link__page" id=m-36getting-startedupgrade><span>Upgrading</span></a></label></li></ul></li><li class="td-sidebar-nav__section-title td-sidebar-nav__section with-child" id=m-36apis-li><input type=checkbox id=m-36apis-check>
<label for=m-36apis-check><a href=/36/apis/ class="align-left ps-0 td-sidebar-link td-sidebar-link__section" id=m-36apis><span>APIs</span></a></label><ul class="ul-2 foldable"><li class="td-sidebar-nav__section-title td-sidebar-nav__section without-child" id=m-36apisapi-li><input type=checkbox id=m-36apisapi-check>
<label for=m-36apisapi-check><a href=/36/apis/api/ class="align-left ps-0 td-sidebar-link td-sidebar-link__page" id=m-36apisapi><span>API</span></a></label></li></ul></li><li class="td-sidebar-nav__section-title td-sidebar-nav__section with-child" id=m-36configuration-li><input type=checkbox id=m-36configuration-check>
<label for=m-36configuration-check><a href=/36/configuration/ class="align-left ps-0 td-sidebar-link td-sidebar-link__section" id=m-36configuration><span>Configuration</span></a></label><ul class="ul-2 foldable"><li class="td-sidebar-nav__section-title td-sidebar-nav__section without-child" id=m-36configurationconfiguration-li><input type=checkbox id=m-36configurationconfiguration-check>
<label for=m-36configurationconfiguration-check><a href=/36/configuration/configuration/ class="align-left ps-0 td-sidebar-link td-sidebar-link__page" id=m-36configurationconfiguration><span>Configuration</span></a></label></li></ul></li><li class="td-sidebar-nav__section-title td-sidebar-nav__section with-child" id=m-36design-li><input type=checkbox id=m-36design-check>
<label for=m-36design-check><a href=/36/design/ class="align-left ps-0 td-sidebar-link td-sidebar-link__section" id=m-36design><span>Design</span></a></label><ul class="ul-2 foldable"><li class="td-sidebar-nav__section-title td-sidebar-nav__section without-child" id=m-36designdesign-li><input type=checkbox id=m-36designdesign-check>
<label for=m-36designdesign-check><a href=/36/design/design/ class="align-left ps-0 td-sidebar-link td-sidebar-link__page" id=m-36designdesign><span>Design</span></a></label></li><li class="td-sidebar-nav__section-title td-sidebar-nav__section without-child" id=m-36designprotocol-li><input type=checkbox id=m-36designprotocol-check>
<label for=m-36designprotocol-check><a href=/36/design/protocol/ class="align-left ps-0 td-sidebar-link td-sidebar-link__page" id=m-36designprotocol><span>Protocol</span></a></label></li></ul></li><li class="td-sidebar-nav__section-title td-sidebar-nav__section with-child" id=m-36implementation-li><input type=checkbox id=m-36implementation-check>
<label for=m-36implementation-check><a href=/36/implementation/ class="align-left ps-0 td-sidebar-link td-sidebar-link__section" id=m-36implementation><span>Implementation</span></a></label><ul class="ul-2 foldable"><li class="td-sidebar-nav__section-title td-sidebar-nav__section without-child" id=m-36implementationnetwork-layer-li><input type=checkbox id=m-36implementationnetwork-layer-check>
<label for=m-36implementationnetwork-layer-check><a href=/36/implementation/network-layer/ class="align-left ps-0 td-sidebar-link td-sidebar-link__page" id=m-36implementationnetwork-layer><span>Network Layer</span></a></label></li><li class="td-sidebar-nav__section-title td-sidebar-nav__section without-child" id=m-36implementationmessages-li><input type=checkbox id=m-36implementationmessages-check>
<label for=m-36implementationmessages-check><a href=/36/implementation/messages/ class="align-left ps-0 td-sidebar-link td-sidebar-link__page" id=m-36implementationmessages><span>Messages</span></a></label></li><li class="td-sidebar-nav__section-title td-sidebar-nav__section without-child" id=m-36implementationmessage-format-li><input type=checkbox id=m-36implementationmessage-format-check>
<label for=m-36implementationmessage-format-check><a href=/36/implementation/message-format/ class="align-left ps-0 td-sidebar-link td-sidebar-link__page" id=m-36implementationmessage-format><span>Message Format</span></a></label></li><li class="td-sidebar-nav__section-title td-sidebar-nav__section without-child" id=m-36implementationlog-li><input type=checkbox id=m-36implementationlog-check>
<label for=m-36implementationlog-check><a href=/36/implementation/log/ class="align-left ps-0 td-sidebar-link td-sidebar-link__page" id=m-36implementationlog><span>Log</span></a></label></li><li class="td-sidebar-nav__section-title td-sidebar-nav__section without-child" id=m-36implementationdistribution-li><input type=checkbox id=m-36implementationdistribution-check>
<label for=m-36implementationdistribution-check><a href=/36/implementation/distribution/ class="align-left ps-0 td-sidebar-link td-sidebar-link__page" id=m-36implementationdistribution><span>Distribution</span></a></label></li></ul></li><li class="td-sidebar-nav__section-title td-sidebar-nav__section with-child" id=m-36operations-li><input type=checkbox id=m-36operations-check>
<label for=m-36operations-check><a href=/36/operations/ class="align-left ps-0 td-sidebar-link td-sidebar-link__section" id=m-36operations><span>Operations</span></a></label><ul class="ul-2 foldable"><li class="td-sidebar-nav__section-title td-sidebar-nav__section without-child" id=m-36operationsbasic-kafka-operations-li><input type=checkbox id=m-36operationsbasic-kafka-operations-check>
<label for=m-36operationsbasic-kafka-operations-check><a href=/36/operations/basic-kafka-operations/ class="align-left ps-0 td-sidebar-link td-sidebar-link__page" id=m-36operationsbasic-kafka-operations><span>Basic Kafka Operations</span></a></label></li><li class="td-sidebar-nav__section-title td-sidebar-nav__section without-child" id=m-36operationsdatacenters-li><input type=checkbox id=m-36operationsdatacenters-check>
<label for=m-36operationsdatacenters-check><a href=/36/operations/datacenters/ class="align-left ps-0 td-sidebar-link td-sidebar-link__page" id=m-36operationsdatacenters><span>Datacenters</span></a></label></li><li class="td-sidebar-nav__section-title td-sidebar-nav__section without-child" id=m-36operationsgeo-replication-cross-cluster-data-mirroring-li><input type=checkbox id=m-36operationsgeo-replication-cross-cluster-data-mirroring-check>
<label for=m-36operationsgeo-replication-cross-cluster-data-mirroring-check><a href=/36/operations/geo-replication-cross-cluster-data-mirroring/ class="align-left ps-0 td-sidebar-link td-sidebar-link__page" id=m-36operationsgeo-replication-cross-cluster-data-mirroring><span>Geo-Replication (Cross-Cluster Data Mirroring)</span></a></label></li><li class="td-sidebar-nav__section-title td-sidebar-nav__section without-child" id=m-36operationsmulti-tenancy-li><input type=checkbox id=m-36operationsmulti-tenancy-check>
<label for=m-36operationsmulti-tenancy-check><a href=/36/operations/multi-tenancy/ class="align-left ps-0 td-sidebar-link td-sidebar-link__page" id=m-36operationsmulti-tenancy><span>Multi-Tenancy</span></a></label></li><li class="td-sidebar-nav__section-title td-sidebar-nav__section without-child" id=m-36operationskafka-configuration-li><input type=checkbox id=m-36operationskafka-configuration-check>
<label for=m-36operationskafka-configuration-check><a href=/36/operations/kafka-configuration/ class="align-left ps-0 td-sidebar-link td-sidebar-link__page" id=m-36operationskafka-configuration><span>Kafka Configuration</span></a></label></li><li class="td-sidebar-nav__section-title td-sidebar-nav__section without-child" id=m-36operationsjava-version-li><input type=checkbox id=m-36operationsjava-version-check>
<label for=m-36operationsjava-version-check><a href=/36/operations/java-version/ class="align-left ps-0 td-sidebar-link td-sidebar-link__page" id=m-36operationsjava-version><span>Java Version</span></a></label></li><li class="td-sidebar-nav__section-title td-sidebar-nav__section without-child" id=m-36operationshardware-and-os-li><input type=checkbox id=m-36operationshardware-and-os-check>
<label for=m-36operationshardware-and-os-check><a href=/36/operations/hardware-and-os/ class="align-left ps-0 td-sidebar-link td-sidebar-link__page" id=m-36operationshardware-and-os><span>Hardware and OS</span></a></label></li><li class="td-sidebar-nav__section-title td-sidebar-nav__section without-child" id=m-36operationsmonitoring-li><input type=checkbox id=m-36operationsmonitoring-check>
<label for=m-36operationsmonitoring-check><a href=/36/operations/monitoring/ class="align-left ps-0 td-sidebar-link td-sidebar-link__page" id=m-36operationsmonitoring><span>Monitoring</span></a></label></li><li class="td-sidebar-nav__section-title td-sidebar-nav__section without-child" id=m-36operationszookeeper-li><input type=checkbox id=m-36operationszookeeper-check>
<label for=m-36operationszookeeper-check><a href=/36/operations/zookeeper/ class="align-left ps-0 td-sidebar-link td-sidebar-link__page" id=m-36operationszookeeper><span>ZooKeeper</span></a></label></li><li class="td-sidebar-nav__section-title td-sidebar-nav__section without-child" id=m-36operationskraft-li><input type=checkbox id=m-36operationskraft-check>
<label for=m-36operationskraft-check><a href=/36/operations/kraft/ class="align-left ps-0 td-sidebar-link td-sidebar-link__page" id=m-36operationskraft><span>KRaft</span></a></label></li><li class="td-sidebar-nav__section-title td-sidebar-nav__section without-child" id=m-36operationstiered-storage-li><input type=checkbox id=m-36operationstiered-storage-check>
<label for=m-36operationstiered-storage-check><a href=/36/operations/tiered-storage/ class="align-left ps-0 td-sidebar-link td-sidebar-link__page" id=m-36operationstiered-storage><span>Tiered Storage</span></a></label></li></ul></li><li class="td-sidebar-nav__section-title td-sidebar-nav__section with-child" id=m-36security-li><input type=checkbox id=m-36security-check>
<label for=m-36security-check><a href=/36/security/ class="align-left ps-0 td-sidebar-link td-sidebar-link__section" id=m-36security><span>Security</span></a></label><ul class="ul-2 foldable"><li class="td-sidebar-nav__section-title td-sidebar-nav__section without-child" id=m-36securitysecurity-overview-li><input type=checkbox id=m-36securitysecurity-overview-check>
<label for=m-36securitysecurity-overview-check><a href=/36/security/security-overview/ class="align-left ps-0 td-sidebar-link td-sidebar-link__page" id=m-36securitysecurity-overview><span>Security Overview</span></a></label></li><li class="td-sidebar-nav__section-title td-sidebar-nav__section without-child" id=m-36securitylistener-configuration-li><input type=checkbox id=m-36securitylistener-configuration-check>
<label for=m-36securitylistener-configuration-check><a href=/36/security/listener-configuration/ class="align-left ps-0 td-sidebar-link td-sidebar-link__page" id=m-36securitylistener-configuration><span>Listener Configuration</span></a></label></li><li class="td-sidebar-nav__section-title td-sidebar-nav__section without-child" id=m-36securityencryption-and-authentication-using-ssl-li><input type=checkbox id=m-36securityencryption-and-authentication-using-ssl-check>
<label for=m-36securityencryption-and-authentication-using-ssl-check><a href=/36/security/encryption-and-authentication-using-ssl/ class="align-left ps-0 td-sidebar-link td-sidebar-link__page" id=m-36securityencryption-and-authentication-using-ssl><span>Encryption and Authentication using SSL</span></a></label></li><li class="td-sidebar-nav__section-title td-sidebar-nav__section without-child" id=m-36securityauthentication-using-sasl-li><input type=checkbox id=m-36securityauthentication-using-sasl-check>
<label for=m-36securityauthentication-using-sasl-check><a href=/36/security/authentication-using-sasl/ class="align-left ps-0 td-sidebar-link td-sidebar-link__page" id=m-36securityauthentication-using-sasl><span>Authentication using SASL</span></a></label></li><li class="td-sidebar-nav__section-title td-sidebar-nav__section without-child" id=m-36securityauthorization-and-acls-li><input type=checkbox id=m-36securityauthorization-and-acls-check>
<label for=m-36securityauthorization-and-acls-check><a href=/36/security/authorization-and-acls/ class="align-left ps-0 td-sidebar-link td-sidebar-link__page" id=m-36securityauthorization-and-acls><span>Authorization and ACLs</span></a></label></li><li class="td-sidebar-nav__section-title td-sidebar-nav__section without-child" id=m-36securityincorporating-security-features-in-a-running-cluster-li><input type=checkbox id=m-36securityincorporating-security-features-in-a-running-cluster-check>
<label for=m-36securityincorporating-security-features-in-a-running-cluster-check><a href=/36/security/incorporating-security-features-in-a-running-cluster/ class="align-left ps-0 td-sidebar-link td-sidebar-link__page" id=m-36securityincorporating-security-features-in-a-running-cluster><span>Incorporating Security Features in a Running Cluster</span></a></label></li><li class="td-sidebar-nav__section-title td-sidebar-nav__section without-child" id=m-36securityzookeeper-authentication-li><input type=checkbox id=m-36securityzookeeper-authentication-check>
<label for=m-36securityzookeeper-authentication-check><a href=/36/security/zookeeper-authentication/ class="align-left ps-0 td-sidebar-link td-sidebar-link__page" id=m-36securityzookeeper-authentication><span>ZooKeeper Authentication</span></a></label></li><li class="td-sidebar-nav__section-title td-sidebar-nav__section without-child" id=m-36securityzookeeper-encryption-li><input type=checkbox id=m-36securityzookeeper-encryption-check>
<label for=m-36securityzookeeper-encryption-check><a href=/36/security/zookeeper-encryption/ class="align-left ps-0 td-sidebar-link td-sidebar-link__page" id=m-36securityzookeeper-encryption><span>ZooKeeper Encryption</span></a></label></li></ul></li><li class="td-sidebar-nav__section-title td-sidebar-nav__section with-child" id=m-36kafka-connect-li><input type=checkbox id=m-36kafka-connect-check>
<label for=m-36kafka-connect-check><a href=/36/kafka-connect/ class="align-left ps-0 td-sidebar-link td-sidebar-link__section" id=m-36kafka-connect><span>Kafka Connect</span></a></label><ul class="ul-2 foldable"><li class="td-sidebar-nav__section-title td-sidebar-nav__section without-child" id=m-36kafka-connectoverview-li><input type=checkbox id=m-36kafka-connectoverview-check>
<label for=m-36kafka-connectoverview-check><a href=/36/kafka-connect/overview/ class="align-left ps-0 td-sidebar-link td-sidebar-link__page" id=m-36kafka-connectoverview><span>Overview</span></a></label></li><li class="td-sidebar-nav__section-title td-sidebar-nav__section without-child" id=m-36kafka-connectuser-guide-li><input type=checkbox id=m-36kafka-connectuser-guide-check>
<label for=m-36kafka-connectuser-guide-check><a href=/36/kafka-connect/user-guide/ class="align-left ps-0 td-sidebar-link td-sidebar-link__page" id=m-36kafka-connectuser-guide><span>User Guide</span></a></label></li><li class="td-sidebar-nav__section-title td-sidebar-nav__section without-child" id=m-36kafka-connectconnector-development-guide-li><input type=checkbox id=m-36kafka-connectconnector-development-guide-check>
<label for=m-36kafka-connectconnector-development-guide-check><a href=/36/kafka-connect/connector-development-guide/ class="align-left ps-0 td-sidebar-link td-sidebar-link__page" id=m-36kafka-connectconnector-development-guide><span>Connector Development Guide</span></a></label></li><li class="td-sidebar-nav__section-title td-sidebar-nav__section without-child" id=m-36kafka-connectadministration-li><input type=checkbox id=m-36kafka-connectadministration-check>
<label for=m-36kafka-connectadministration-check><a href=/36/kafka-connect/administration/ class="align-left ps-0 td-sidebar-link td-sidebar-link__page" id=m-36kafka-connectadministration><span>Administration</span></a></label></li></ul></li><li class="td-sidebar-nav__section-title td-sidebar-nav__section with-child active-path" id=m-36streams-li><input type=checkbox id=m-36streams-check checked>
<label for=m-36streams-check><a href=/36/streams/ class="align-left ps-0 td-sidebar-link td-sidebar-link__section" id=m-36streams><span>Kafka Streams</span></a></label><ul class="ul-2 foldable"><li class="td-sidebar-nav__section-title td-sidebar-nav__section without-child" id=m-36streamsintroduction-li><input type=checkbox id=m-36streamsintroduction-check>
<label for=m-36streamsintroduction-check><a href=/36/streams/introduction/ class="align-left ps-0 td-sidebar-link td-sidebar-link__page" id=m-36streamsintroduction><span>Introduction</span></a></label></li><li class="td-sidebar-nav__section-title td-sidebar-nav__section without-child" id=m-36streamsquickstart-li><input type=checkbox id=m-36streamsquickstart-check>
<label for=m-36streamsquickstart-check><a href=/36/streams/quickstart/ class="align-left ps-0 td-sidebar-link td-sidebar-link__page" id=m-36streamsquickstart><span>Quick Start</span></a></label></li><li class="td-sidebar-nav__section-title td-sidebar-nav__section without-child" id=m-36streamstutorial-li><input type=checkbox id=m-36streamstutorial-check>
<label for=m-36streamstutorial-check><a href=/36/streams/tutorial/ class="align-left ps-0 td-sidebar-link td-sidebar-link__page" id=m-36streamstutorial><span>Write a streams app</span></a></label></li><li class="td-sidebar-nav__section-title td-sidebar-nav__section without-child" id=m-36streamscore-concepts-li><input type=checkbox id=m-36streamscore-concepts-check>
<label for=m-36streamscore-concepts-check><a href=/36/streams/core-concepts/ class="align-left ps-0 td-sidebar-link td-sidebar-link__page" id=m-36streamscore-concepts><span>Core Concepts</span></a></label></li><li class="td-sidebar-nav__section-title td-sidebar-nav__section without-child" id=m-36streamsarchitecture-li><input type=checkbox id=m-36streamsarchitecture-check>
<label for=m-36streamsarchitecture-check><a href=/36/streams/architecture/ class="align-left ps-0 td-sidebar-link td-sidebar-link__page" id=m-36streamsarchitecture><span>Architecture</span></a></label></li><li class="td-sidebar-nav__section-title td-sidebar-nav__section without-child" id=m-36streamsupgrade-guide-li><input type=checkbox id=m-36streamsupgrade-guide-check>
<label for=m-36streamsupgrade-guide-check><a href=/36/streams/upgrade-guide/ class="align-left ps-0 td-sidebar-link td-sidebar-link__page" id=m-36streamsupgrade-guide><span>Upgrade Guide</span></a></label></li><li class="td-sidebar-nav__section-title td-sidebar-nav__section with-child active-path" id=m-36streamsdeveloper-guide-li><input type=checkbox id=m-36streamsdeveloper-guide-check checked>
<label for=m-36streamsdeveloper-guide-check><a href=/36/streams/developer-guide/ class="align-left ps-0 td-sidebar-link td-sidebar-link__section" id=m-36streamsdeveloper-guide><span>Streams Developer Guide</span></a></label><ul class="ul-3 foldable"><li class="td-sidebar-nav__section-title td-sidebar-nav__section without-child" id=m-36streamsdeveloper-guidewrite-streams-app-li><input type=checkbox id=m-36streamsdeveloper-guidewrite-streams-app-check>
<label for=m-36streamsdeveloper-guidewrite-streams-app-check><a href=/36/streams/developer-guide/write-streams-app/ class="align-left ps-0 td-sidebar-link td-sidebar-link__page" id=m-36streamsdeveloper-guidewrite-streams-app><span>Writing a Streams Application</span></a></label></li><li class="td-sidebar-nav__section-title td-sidebar-nav__section without-child" id=m-36streamsdeveloper-guideconfig-streams-li><input type=checkbox id=m-36streamsdeveloper-guideconfig-streams-check>
<label for=m-36streamsdeveloper-guideconfig-streams-check><a href=/36/streams/developer-guide/config-streams/ class="align-left ps-0 td-sidebar-link td-sidebar-link__page" id=m-36streamsdeveloper-guideconfig-streams><span>Configuring a Streams Application</span></a></label></li><li class="td-sidebar-nav__section-title td-sidebar-nav__section without-child" id=m-36streamsdeveloper-guidedsl-api-li><input type=checkbox id=m-36streamsdeveloper-guidedsl-api-check>
<label for=m-36streamsdeveloper-guidedsl-api-check><a href=/36/streams/developer-guide/dsl-api/ class="align-left ps-0 td-sidebar-link td-sidebar-link__page" id=m-36streamsdeveloper-guidedsl-api><span>Streams DSL</span></a></label></li><li class="td-sidebar-nav__section-title td-sidebar-nav__section without-child active-path" id=m-36streamsdeveloper-guideprocessor-api-li><input type=checkbox id=m-36streamsdeveloper-guideprocessor-api-check checked>
<label for=m-36streamsdeveloper-guideprocessor-api-check><a href=/36/streams/developer-guide/processor-api/ class="align-left ps-0 active td-sidebar-link td-sidebar-link__page" id=m-36streamsdeveloper-guideprocessor-api><span class=td-sidebar-nav-active-item>Processor API</span></a></label></li><li class="td-sidebar-nav__section-title td-sidebar-nav__section without-child" id=m-36streamsdeveloper-guidedsl-topology-naming-li><input type=checkbox id=m-36streamsdeveloper-guidedsl-topology-naming-check>
<label for=m-36streamsdeveloper-guidedsl-topology-naming-check><a href=/36/streams/developer-guide/dsl-topology-naming/ class="align-left ps-0 td-sidebar-link td-sidebar-link__page" id=m-36streamsdeveloper-guidedsl-topology-naming><span>Naming Operators in a Streams DSL application</span></a></label></li><li class="td-sidebar-nav__section-title td-sidebar-nav__section without-child" id=m-36streamsdeveloper-guidedatatypes-li><input type=checkbox id=m-36streamsdeveloper-guidedatatypes-check>
<label for=m-36streamsdeveloper-guidedatatypes-check><a href=/36/streams/developer-guide/datatypes/ class="align-left ps-0 td-sidebar-link td-sidebar-link__page" id=m-36streamsdeveloper-guidedatatypes><span>Data Types and Serialization</span></a></label></li><li class="td-sidebar-nav__section-title td-sidebar-nav__section without-child" id=m-36streamsdeveloper-guidetesting-li><input type=checkbox id=m-36streamsdeveloper-guidetesting-check>
<label for=m-36streamsdeveloper-guidetesting-check><a href=/36/streams/developer-guide/testing/ class="align-left ps-0 td-sidebar-link td-sidebar-link__page" id=m-36streamsdeveloper-guidetesting><span>Testing a Streams Application</span></a></label></li><li class="td-sidebar-nav__section-title td-sidebar-nav__section without-child" id=m-36streamsdeveloper-guideinteractive-queries-li><input type=checkbox id=m-36streamsdeveloper-guideinteractive-queries-check>
<label for=m-36streamsdeveloper-guideinteractive-queries-check><a href=/36/streams/developer-guide/interactive-queries/ class="align-left ps-0 td-sidebar-link td-sidebar-link__page" id=m-36streamsdeveloper-guideinteractive-queries><span>Interactive Queries</span></a></label></li><li class="td-sidebar-nav__section-title td-sidebar-nav__section without-child" id=m-36streamsdeveloper-guidememory-mgmt-li><input type=checkbox id=m-36streamsdeveloper-guidememory-mgmt-check>
<label for=m-36streamsdeveloper-guidememory-mgmt-check><a href=/36/streams/developer-guide/memory-mgmt/ class="align-left ps-0 td-sidebar-link td-sidebar-link__page" id=m-36streamsdeveloper-guidememory-mgmt><span>Memory Management</span></a></label></li><li class="td-sidebar-nav__section-title td-sidebar-nav__section without-child" id=m-36streamsdeveloper-guiderunning-app-li><input type=checkbox id=m-36streamsdeveloper-guiderunning-app-check>
<label for=m-36streamsdeveloper-guiderunning-app-check><a href=/36/streams/developer-guide/running-app/ class="align-left ps-0 td-sidebar-link td-sidebar-link__page" id=m-36streamsdeveloper-guiderunning-app><span>Running Streams Applications</span></a></label></li><li class="td-sidebar-nav__section-title td-sidebar-nav__section without-child" id=m-36streamsdeveloper-guidemanage-topics-li><input type=checkbox id=m-36streamsdeveloper-guidemanage-topics-check>
<label for=m-36streamsdeveloper-guidemanage-topics-check><a href=/36/streams/developer-guide/manage-topics/ class="align-left ps-0 td-sidebar-link td-sidebar-link__page" id=m-36streamsdeveloper-guidemanage-topics><span>Managing Streams Application Topics</span></a></label></li><li class="td-sidebar-nav__section-title td-sidebar-nav__section without-child" id=m-36streamsdeveloper-guidesecurity-li><input type=checkbox id=m-36streamsdeveloper-guidesecurity-check>
<label for=m-36streamsdeveloper-guidesecurity-check><a href=/36/streams/developer-guide/security/ class="align-left ps-0 td-sidebar-link td-sidebar-link__page" id=m-36streamsdeveloper-guidesecurity><span>Streams Security</span></a></label></li><li class="td-sidebar-nav__section-title td-sidebar-nav__section without-child" id=m-36streamsdeveloper-guideapp-reset-tool-li><input type=checkbox id=m-36streamsdeveloper-guideapp-reset-tool-check>
<label for=m-36streamsdeveloper-guideapp-reset-tool-check><a href=/36/streams/developer-guide/app-reset-tool/ class="align-left ps-0 td-sidebar-link td-sidebar-link__page" id=m-36streamsdeveloper-guideapp-reset-tool><span>Application Reset Tool</span></a></label></li></ul></li></ul></li></ul></li></ul></nav></div></aside><aside class="d-none d-xl-block col-xl-2 td-sidebar-toc d-print-none"><div class="td-page-meta ms-2 pb-1 pt-2 mb-0"><a href=https://github.com/apache/kafka-site//tree/markdown/content/en/36/streams/developer-guide/processor-api.md class="td-page-meta--view td-page-meta__view" target=_blank rel=noopener><i class="fa-solid fa-file-lines fa-fw"></i> View page source</a>
<a href=https://github.com/apache/kafka-site//edit/markdown/content/en/36/streams/developer-guide/processor-api.md class="td-page-meta--edit td-page-meta__edit" target=_blank rel=noopener><i class="fa-solid fa-pen-to-square fa-fw"></i> Edit this page</a>
<a href="https://github.com/apache/kafka-site//new/markdown/content/en/36/streams/developer-guide?filename=change-me.md&amp;value=---%0Atitle%3A+%22Long+Page+Title%22%0AlinkTitle%3A+%22Short+Nav+Title%22%0Aweight%3A+100%0Adescription%3A+%3E-%0A+++++Page+description+for+heading+and+indexes.%0A---%0A%0A%23%23+Heading%0A%0AEdit+this+template+to+create+your+new+page.%0A%0A%2A+Give+it+a+good+name%2C+ending+in+%60.md%60+-+e.g.+%60getting-started.md%60%0A%2A+Edit+the+%22front+matter%22+section+at+the+top+of+the+page+%28weight+controls+how+its+ordered+amongst+other+pages+in+the+same+directory%3B+lowest+number+first%29.%0A%2A+Add+a+good+commit+message+at+the+bottom+of+the+page+%28%3C80+characters%3B+use+the+extended+description+field+for+more+detail%29.%0A%2A+Create+a+new+branch+so+you+can+preview+your+new+file+and+request+a+review+via+Pull+Request.%0A" class="td-page-meta--child td-page-meta__child" target=_blank rel=noopener><i class="fa-solid fa-pen-to-square fa-fw"></i> Create child page</a>
<a href="https://github.com/apache/kafka-site//issues/new?title=Processor%20API" class="td-page-meta--issue td-page-meta__issue" target=_blank rel=noopener><i class="fa-solid fa-list-check fa-fw"></i> Create documentation issue</a>
<a id=print href=/36/streams/developer-guide/_print/><i class="fa-solid fa-print fa-fw"></i> Print entire section</a></div><div class="taxonomy taxonomy-terms-cloud taxo-tags"><h5 class=taxonomy-title>Tag Cloud</h5><ul class=taxonomy-terms><li><a class=taxonomy-term href=https://example.kafka-site-md.dev/tags/apis/ data-taxonomy-term=apis><span class=taxonomy-label>Apis</span><span class=taxonomy-count>32</span></a></li><li><a class=taxonomy-term href=https://example.kafka-site-md.dev/tags/configuration/ data-taxonomy-term=configuration><span class=taxonomy-label>Configuration</span><span class=taxonomy-count>32</span></a></li><li><a class=taxonomy-term href=https://example.kafka-site-md.dev/tags/design/ data-taxonomy-term=design><span class=taxonomy-label>Design</span><span class=taxonomy-count>32</span></a></li><li><a class=taxonomy-term href=https://example.kafka-site-md.dev/tags/developer-guide/ data-taxonomy-term=developer-guide><span class=taxonomy-label>Developer-Guide</span><span class=taxonomy-count>32</span></a></li><li><a class=taxonomy-term href=https://example.kafka-site-md.dev/tags/docs/ data-taxonomy-term=docs><span class=taxonomy-label>Docs</span><span class=taxonomy-count>1781</span></a></li><li><a class=taxonomy-term href=https://example.kafka-site-md.dev/tags/getting-started/ data-taxonomy-term=getting-started><span class=taxonomy-label>Getting-Started</span><span class=taxonomy-count>32</span></a></li><li><a class=taxonomy-term href=https://example.kafka-site-md.dev/tags/implementation/ data-taxonomy-term=implementation><span class=taxonomy-label>Implementation</span><span class=taxonomy-count>32</span></a></li><li><a class=taxonomy-term href=https://example.kafka-site-md.dev/tags/kafka/ data-taxonomy-term=kafka><span class=taxonomy-label>Kafka</span><span class=taxonomy-count>1781</span></a></li><li><a class=taxonomy-term href=https://example.kafka-site-md.dev/tags/ops/ data-taxonomy-term=ops><span class=taxonomy-label>Ops</span><span class=taxonomy-count>32</span></a></li><li><a class=taxonomy-term href=https://example.kafka-site-md.dev/tags/security/ data-taxonomy-term=security><span class=taxonomy-label>Security</span><span class=taxonomy-count>64</span></a></li><li><a class=taxonomy-term href=https://example.kafka-site-md.dev/tags/streams/ data-taxonomy-term=streams><span class=taxonomy-label>Streams</span><span class=taxonomy-count>64</span></a></li></ul></div></aside><main class="col-12 col-md-9 col-xl-8 ps-md-5" role=main><div class="pageinfo pageinfo-warning"><p>You are viewing documentation for an older version (3.6) of Kafka.
For up-to-date documentation, see the
<a href=/41/ target=_blank>latest version</a>.</p></div><nav aria-label=breadcrumb class=td-breadcrumbs><ol class=breadcrumb><li class=breadcrumb-item><a href=/36/>AK 3.6.X</a></li><li class=breadcrumb-item><a href=/36/streams/>Kafka Streams</a></li><li class=breadcrumb-item><a href=/36/streams/developer-guide/>Streams Developer Guide</a></li><li class="breadcrumb-item active" aria-current=page>Processor API</li></ol></nav><div class=td-content><h1>Processor API</h1><header class=article-meta><div class="taxonomy taxonomy-terms-article taxo-tags"><h5 class=taxonomy-title>Tags:</h5><ul class=taxonomy-terms><li><a class=taxonomy-term href=https://example.kafka-site-md.dev/tags/kafka/ data-taxonomy-term=kafka><span class=taxonomy-label>Kafka</span></a></li><li><a class=taxonomy-term href=https://example.kafka-site-md.dev/tags/docs/ data-taxonomy-term=docs><span class=taxonomy-label>Docs</span></a></li></ul></div></header><h1 id=processor-api>Processor API<a class=td-heading-self-link href=#processor-api aria-label="Heading self-link"></a></h1><p>The Processor API allows developers to define and connect custom processors and to interact with state stores. With the Processor API, you can define arbitrary stream processors that process one received record at a time, and connect these processors with their associated state stores to compose the processor topology that represents a customized processing logic.</p><p><strong>Table of Contents</strong></p><ul><li>Overview</li><li>Defining a Stream Processor</li><li>Unit Testing Processors</li><li>State Stores<ul><li>Defining and creating a State Store</li><li>Fault-tolerant State Stores</li><li>Enable or Disable Fault Tolerance of State Stores (Store Changelogs)</li><li>Timestamped State Stores</li><li>Versioned Key-Value State Stores</li><li>Implementing Custom State Stores</li></ul></li><li>Connecting Processors and State Stores</li><li>Accessing Processor Context</li></ul><h1 id=overview>Overview<a class=td-heading-self-link href=#overview aria-label="Heading self-link"></a></h1><p>The Processor API can be used to implement both <strong>stateless</strong> as well as <strong>stateful</strong> operations, where the latter is achieved through the use of state stores.</p><p><strong>Tip</strong></p><p><strong>Combining the DSL and the Processor API:</strong> You can combine the convenience of the DSL with the power and flexibility of the Processor API as described in the section <a href=/36/streams/developer-guide/dsl-api/#streams-developer-guide-dsl-process>Applying processors and transformers (Processor API integration)</a>.</p><p>For a complete list of available API functionality, see the <a href=/36/javadoc/org/apache/kafka/streams/package-summary.html>Streams</a> API docs.</p><h1 id=defining-a-stream-processor>Defining a Stream Processor<a class=td-heading-self-link href=#defining-a-stream-processor aria-label="Heading self-link"></a></h1><p>A <a href=/36/streams/core-concepts/#streams_processor_node>stream processor</a> is a node in the processor topology that represents a single processing step. With the Processor API, you can define arbitrary stream processors that processes one received record at a time, and connect these processors with their associated state stores to compose the processor topology.</p><p>You can define a customized stream processor by implementing the <code>Processor</code> interface, which provides the <code>process()</code> API method. The <code>process()</code> method is called on each of the received records.</p><p>The <code>Processor</code> interface also has an <code>init()</code> method, which is called by the Kafka Streams library during task construction phase. Processor instances should perform any required initialization in this method. The <code>init()</code> method passes in a <code>ProcessorContext</code> instance, which provides access to the metadata of the currently processed record, including its source Kafka topic and partition, its corresponding message offset, and further such information. You can also use this context instance to schedule a punctuation function (via <code>ProcessorContext#schedule()</code>), to forward a new record as a key-value pair to the downstream processors (via <code>ProcessorContext#forward()</code>), and to commit the current processing progress (via <code>ProcessorContext#commit()</code>). Any resources you set up in <code>init()</code> can be cleaned up in the <code>close()</code> method. Note that Kafka Streams may re-use a single <code>Processor</code> object by calling <code>init()</code> on it again after <code>close()</code>.</p><p>The <code>Processor</code> interface takes two sets of generic parameters: <code>KIn, VIn, KOut, VOut</code>. These define the input and output types that the processor implementation can handle. <code>KIn</code> and <code>VIn</code> define the key and value types that will be passed to <code>process()</code>. Likewise, <code>KOut</code> and <code>VOut</code> define the forwarded key and value types that <code>ProcessorContext#forward()</code> will accept. If your processor does not forward any records at all (or if it only forwards <code>null</code> keys or values), a best practice is to set the output generic type argument to <code>Void</code>. If it needs to forward multiple types that don&rsquo;t share a common superclass, you will have to set the output generic type argument to <code>Object</code>.</p><p>Both the <code>Processor#process()</code> and the <code>ProcessorContext#forward()</code> methods handle records in the form of the <code>Record&lt;K, V></code> data class. This class gives you access to the main components of a Kafka record: the key, value, timestamp and headers. When forwarding records, you can use the constructor to create a new <code>Record</code> from scratch, or you can use the convenience builder methods to replace one of the <code>Record</code>&rsquo;s properties and copy over the rest. For example, <code>inputRecord.withValue(newValue)</code> would copy the key, timestamp, and headers from <code>inputRecord</code> while setting the output record&rsquo;s value to <code>newValue</code>. Note that this does not mutate <code>inputRecord</code>, but instead creates a shallow copy. Beware that this is only a shallow copy, so if you plan to mutate the key, value, or headers elsewhere in the program, you will want to create a deep copy of those fields yourself.</p><p>In addition to handling incoming records via <code>Processor#process()</code>, you have the option to schedule periodic invocation (called &ldquo;punctuation&rdquo;) in your processor&rsquo;s <code>init()</code> method by calling <code>ProcessorContext#schedule()</code> and passing it a <code>Punctuator</code>. The <code>PunctuationType</code> determines what notion of time is used for the punctuation scheduling: either <a href=/36/streams/core-concepts/#streams_time>stream-time</a> or wall-clock-time (by default, stream-time is configured to represent event-time via <code>TimestampExtractor</code>). When stream-time is used, <code>punctuate()</code> is triggered purely by data because stream-time is determined (and advanced forward) by the timestamps derived from the input data. When there is no new input data arriving, stream-time is not advanced and thus <code>punctuate()</code> is not called.</p><p>For example, if you schedule a <code>Punctuator</code> function every 10 seconds based on <code>PunctuationType.STREAM_TIME</code> and if you process a stream of 60 records with consecutive timestamps from 1 (first record) to 60 seconds (last record), then <code>punctuate()</code> would be called 6 times. This happens regardless of the time required to actually process those records. <code>punctuate()</code> would be called 6 times regardless of whether processing these 60 records takes a second, a minute, or an hour.</p><p>When wall-clock-time (i.e. <code>PunctuationType.WALL_CLOCK_TIME</code>) is used, <code>punctuate()</code> is triggered purely by the wall-clock time. Reusing the example above, if the <code>Punctuator</code> function is scheduled based on <code>PunctuationType.WALL_CLOCK_TIME</code>, and if these 60 records were processed within 20 seconds, <code>punctuate()</code> is called 2 times (one time every 10 seconds). If these 60 records were processed within 5 seconds, then no <code>punctuate()</code> is called at all. Note that you can schedule multiple <code>Punctuator</code> callbacks with different <code>PunctuationType</code> types within the same processor by calling <code>ProcessorContext#schedule()</code> multiple times inside <code>init()</code> method.</p><p><strong>Attention</strong></p><p>Stream-time is only advanced when Streams processes records. If there are no records to process, or if Streams is waiting for new records due to the <a href=/#streamsconfigs_max.task.idle.ms>Task Idling</a> configuration, then the stream time will not advance and <code>punctuate()</code> will not be triggered if <code>PunctuationType.STREAM_TIME</code> was specified. This behavior is independent of the configured timestamp extractor, i.e., using <code>WallclockTimestampExtractor</code> does not enable wall-clock triggering of <code>punctuate()</code>.</p><p><strong>Example</strong></p><p>The following example <code>Processor</code> defines a simple word-count algorithm and the following actions are performed:</p><ul><li><p>In the <code>init()</code> method, schedule the punctuation every 1000 time units (the time unit is normally milliseconds, which in this example would translate to punctuation every 1 second) and retrieve the local state store by its name &ldquo;Counts&rdquo;.</p></li><li><p>In the <code>process()</code> method, upon each received record, split the value string into words, and update their counts into the state store (we will talk about this later in this section).</p></li><li><p>In the <code>punctuate()</code> method, iterate the local state store and send the aggregated counts to the downstream processor (we will talk about downstream processors later in this section), and commit the current stream state.</p><p>public class WordCountProcessor implements Processor&lt;String, String, String, String> {
private KeyValueStore&lt;String, Integer> kvStore;</p><pre><code>@Override
public void init(final ProcessorContext&lt;String, String&gt; context) {
    context.schedule(Duration.ofSeconds(1), PunctuationType.STREAM_TIME, timestamp -&gt; {
        try (final KeyValueIterator&lt;String, Integer&gt; iter = kvStore.all()) {
            while (iter.hasNext()) {
                final KeyValue&lt;String, Integer&gt; entry = iter.next();
                context.forward(new Record&lt;&gt;(entry.key, entry.value.toString(), timestamp));
            }
        }
    });
    kvStore = context.getStateStore(&quot;Counts&quot;);
}

@Override
public void process(final Record&lt;String, String&gt; record) {
    final String[] words = record.value().toLowerCase(Locale.getDefault()).split(&quot;\W+&quot;);

    for (final String word : words) {
        final Integer oldValue = kvStore.get(word);

        if (oldValue == null) {
            kvStore.put(word, 1);
        } else {
            kvStore.put(word, oldValue + 1);
        }
    }
}

@Override
public void close() {
    // close any resources managed by this processor
    // Note: Do not close any StateStores as these are managed by the library
}
</code></pre><p>}</p></li></ul><p><strong>Note</strong></p><p><strong>Stateful processing with state stores:</strong> The <code>WordCountProcessor</code> defined above can access the currently received record in its <code>process()</code> method, and it can leverage state stores to maintain processing states to, for example, remember recently arrived records for stateful processing needs like aggregations and joins. For more information, see the state stores documentation.</p><h1 id=unit-testing-processors>Unit Testing Processors<a class=td-heading-self-link href=#unit-testing-processors aria-label="Heading self-link"></a></h1><p>Kafka Streams comes with a <code>test-utils</code> module to help you write unit tests for your processors <a href=/36/streams/developer-guide/testing/#unit-testing-processors>here</a>.</p><h1 id=state-stores>State Stores<a class=td-heading-self-link href=#state-stores aria-label="Heading self-link"></a></h1><p>To implement a <strong>stateful</strong> <code>Processor</code> or <code>Transformer</code>, you must provide one or more state stores to the processor or transformer (<em>stateless</em> processors or transformers do not need state stores). State stores can be used to remember recently received input records, to track rolling aggregates, to de-duplicate input records, and more. Another feature of state stores is that they can be <a href=/36/streams/developer-guide/interactive-queries/#streams-developer-guide-interactive-queries>interactively queried</a> from other applications, such as a NodeJS-based dashboard or a microservice implemented in Scala or Go.</p><p>The available state store types in Kafka Streams have fault tolerance enabled by default.</p><h1 id=defining-and-creating-a-state-store>Defining and creating a State Store<a class=td-heading-self-link href=#defining-and-creating-a-state-store aria-label="Heading self-link"></a></h1><p>You can either use one of the available store types or implement your own custom store type. It&rsquo;s common practice to leverage an existing store type via the <code>Stores</code> factory.</p><p>Note that, when using Kafka Streams, you normally don&rsquo;t create or instantiate state stores directly in your code. Rather, you define state stores indirectly by creating a so-called <code>StoreBuilder</code>. This builder is used by Kafka Streams as a factory to instantiate the actual state stores locally in application instances when and where needed.</p><p>The following store types are available out of the box.</p><table><thead><tr><th>Store Type</th><th>Storage Engine</th><th>Fault-tolerant?</th><th>Description</th></tr></thead><tbody><tr><td>Persistent <code>KeyValueStore&lt;K, V></code></td><td>RocksDB</td><td>Yes (enabled by default)</td><td></td></tr></tbody></table><ul><li><p><strong>The recommended store type for most use cases.</strong></p></li><li><p>Stores its data on local disk.</p></li><li><p>Storage capacity: managed local state can be larger than the memory (heap space) of an application instance, but must fit into the available local disk space.</p></li><li><p>RocksDB settings can be fine-tuned, see <a href=/36/streams/developer-guide/config-streams/#streams-developer-guide-rocksdb-config>RocksDB configuration</a>.</p></li><li><p>Available <a href=/36/javadoc/org/apache/kafka/streams/state/Stores.html#persistentKeyValueStore%5C(java.lang.String%5C)>store variants</a>: timestamped key-value store, versioned key-value store, time window key-value store, session window key-value store.</p></li><li><p>Use <a href=/36/javadoc/org/apache/kafka/streams/state/Stores.html#persistentTimestampedKeyValueStore%5C(java.lang.String%5C)>persistentTimestampedKeyValueStore</a> when you need a persistent key-(value/timestamp) store that supports put/get/delete and range queries.</p></li><li><p>Use <a href=/36/javadoc/org/apache/kafka/streams/state/Stores.html#persistentVersionedKeyValueStore%5C(java.lang.String,java.time.Duration%5C)>persistentVersionedKeyValueStore</a> when you need a persistent, versioned key-(value/timestamp) store that supports put/get/delete and timestamped get operations.</p></li><li><p>Use <a href=/36/javadoc/org/apache/kafka/streams/state/Stores.html#persistentWindowStore%5C(java.lang.String,java.time.Duration,java.time.Duration,boolean%5C)>persistentWindowStore</a> or <a href=/36/javadoc/org/apache/kafka/streams/state/Stores.html#persistentTimestampedWindowStore%5C(java.lang.String,java.time.Duration,java.time.Duration,boolean%5C)>persistentTimestampedWindowStore</a> when you need a persistent timeWindowedKey-value or timeWindowedKey-(value/timestamp) store, respectively.</p></li><li><p>Use <a href=/36/javadoc/org/apache/kafka/streams/state/Stores.html#persistentSessionStore%5C(java.lang.String,java.time.Duration%5C)>persistentSessionStore</a> when you need a persistent sessionWindowedKey-value store.</p><p>// Creating a persistent key-value store:
// here, we create a <code>KeyValueStore&lt;String, Long></code> named &ldquo;persistent-counts&rdquo;.
import org.apache.kafka.streams.state.StoreBuilder;
import org.apache.kafka.streams.state.Stores;</p><p>// Using a <code>KeyValueStoreBuilder</code> to build a <code>KeyValueStore</code>.
StoreBuilder&lt;KeyValueStore&lt;String, Long&#187; countStoreSupplier =
Stores.keyValueStoreBuilder(
Stores.persistentKeyValueStore(&ldquo;persistent-counts&rdquo;),
Serdes.String(),
Serdes.Long());
KeyValueStore&lt;String, Long> countStore = countStoreSupplier.build();</p></li></ul><p>In-memory <code>KeyValueStore&lt;K, V></code> | - | Yes (enabled by default) |</p><ul><li><p>Stores its data in memory.</p></li><li><p>Storage capacity: managed local state must fit into memory (heap space) of an application instance.</p></li><li><p>Useful when application instances run in an environment where local disk space is either not available or local disk space is wiped in-between app instance restarts.</p></li><li><p>Available <a href=/36/javadoc/org/apache/kafka/streams/state/Stores.html#inMemoryKeyValueStore-java.lang.String->store variants</a>: time window key-value store, session window key-value store.</p></li><li><p>Use <a href=/36/javadoc/org/apache/kafka/streams/state/TimestampedKeyValueStore.html>TimestampedKeyValueStore</a> when you need a key-(value/timestamp) store that supports put/get/delete and range queries.</p></li><li><p>Use <a href=/36/javadoc/org/apache/kafka/streams/state/TimestampedWindowStore.html>TimestampedWindowStore</a> when you need to store windowedKey-(value/timestamp) pairs.</p></li><li><p>There is no built-in in-memory, versioned key-value store at this time.</p><p>// Creating an in-memory key-value store:
// here, we create a <code>KeyValueStore&lt;String, Long></code> named &ldquo;inmemory-counts&rdquo;.
import org.apache.kafka.streams.state.StoreBuilder;
import org.apache.kafka.streams.state.Stores;</p><p>// Using a <code>KeyValueStoreBuilder</code> to build a <code>KeyValueStore</code>.
StoreBuilder&lt;KeyValueStore&lt;String, Long&#187; countStoreSupplier =
Stores.keyValueStoreBuilder(
Stores.inMemoryKeyValueStore(&ldquo;inmemory-counts&rdquo;),
Serdes.String(),
Serdes.Long());
KeyValueStore&lt;String, Long> countStore = countStoreSupplier.build();</p></li></ul><h1 id=fault-tolerant-state-stores>Fault-tolerant State Stores<a class=td-heading-self-link href=#fault-tolerant-state-stores aria-label="Heading self-link"></a></h1><p>To make state stores fault-tolerant and to allow for state store migration without data loss, a state store can be continuously backed up to a Kafka topic behind the scenes. For example, to migrate a stateful stream task from one machine to another when <a href=/36/streams/developer-guide/running-app/#streams-developer-guide-execution-scaling>elastically adding or removing capacity from your application</a>. This topic is sometimes referred to as the state store&rsquo;s associated <em>changelog topic</em> , or its <em>changelog</em>. For example, if you experience machine failure, the state store and the application&rsquo;s state can be fully restored from its changelog. You can enable or disable this backup feature for a state store.</p><p>Fault-tolerant state stores are backed by a <a href=https://kafka.apache.org/documentation.html#compaction>compacted</a> changelog topic. The purpose of compacting this topic is to prevent the topic from growing indefinitely, to reduce the storage consumed in the associated Kafka cluster, and to minimize recovery time if a state store needs to be restored from its changelog topic.</p><p>Fault-tolerant windowed state stores are backed by a topic that uses both compaction and deletion. Because of the structure of the message keys that are being sent to the changelog topics, this combination of deletion and compaction is required for the changelog topics of window stores. For window stores, the message keys are composite keys that include the &ldquo;normal&rdquo; key and window timestamps. For these types of composite keys it would not be sufficient to only enable compaction to prevent a changelog topic from growing out of bounds. With deletion enabled, old windows that have expired will be cleaned up by Kafka&rsquo;s log cleaner as the log segments expire. The default retention setting is <code>Windows#maintainMs()</code> + 1 day. You can override this setting by specifying <code>StreamsConfig.WINDOW_STORE_CHANGE_LOG_ADDITIONAL_RETENTION_MS_CONFIG</code> in the <code>StreamsConfig</code>.</p><p>When you open an <code>Iterator</code> from a state store you must call <code>close()</code> on the iterator when you are done working with it to reclaim resources; or you can use the iterator from within a try-with-resources statement. If you do not close an iterator, you may encounter an OOM error.</p><h1 id=enable-or-disable-fault-tolerance-of-state-stores-store-changelogs>Enable or Disable Fault Tolerance of State Stores (Store Changelogs)<a class=td-heading-self-link href=#enable-or-disable-fault-tolerance-of-state-stores-store-changelogs aria-label="Heading self-link"></a></h1><p>You can enable or disable fault tolerance for a state store by enabling or disabling the change logging of the store through <code>enableLogging()</code> and <code>disableLogging()</code>. You can also fine-tune the associated topic&rsquo;s configuration if needed.</p><p>Example for disabling fault-tolerance:</p><pre><code>import org.apache.kafka.streams.state.StoreBuilder;
import org.apache.kafka.streams.state.Stores;

StoreBuilder&lt;KeyValueStore&lt;String, Long&gt;&gt; countStoreSupplier = Stores.keyValueStoreBuilder(
  Stores.persistentKeyValueStore(&quot;Counts&quot;),
    Serdes.String(),
    Serdes.Long())
  .withLoggingDisabled(); // disable backing up the store to a changelog topic
</code></pre><p>Attention</p><p>If the changelog is disabled then the attached state store is no longer fault tolerant and it can&rsquo;t have any <a href=/36/streams/developer-guide/config-streams/#streams-developer-guide-standby-replicas>standby replicas</a>.</p><p>Here is an example for enabling fault tolerance, with additional changelog-topic configuration: You can add any log config from <a href=https://github.com/apache/kafka/blob/trunk/core/src/main/scala/kafka/log/LogConfig.scala>kafka.log.LogConfig</a>. Unrecognized configs will be ignored.</p><pre><code>import org.apache.kafka.streams.state.StoreBuilder;
import org.apache.kafka.streams.state.Stores;

Map&lt;String, String&gt; changelogConfig = new HashMap();
// override min.insync.replicas
changelogConfig.put(TopicConfig.MIN_IN_SYNC_REPLICAS_CONFIG, &quot;1&quot;)

StoreBuilder&lt;KeyValueStore&lt;String, Long&gt;&gt; countStoreSupplier = Stores.keyValueStoreBuilder(
  Stores.persistentKeyValueStore(&quot;Counts&quot;),
    Serdes.String(),
    Serdes.Long())
  .withLoggingEnabled(changelogConfig); // enable changelogging, with custom changelog settings
</code></pre><h1 id=timestamped-state-stores>Timestamped State Stores<a class=td-heading-self-link href=#timestamped-state-stores aria-label="Heading self-link"></a></h1><p>KTables always store timestamps by default. A timestamped state store improves stream processing semantics and enables handling out-of-order data in source KTables, detecting out-of-order joins and aggregations, and getting the timestamp of the latest update in an Interactive Query.</p><p>You can query timestamped state stores both with and without a timestamp.</p><p><strong>Upgrade note:</strong> All users upgrade with a single rolling bounce per instance.</p><ul><li>For Processor API users, nothing changes in existing applications, and you have the option of using the timestamped stores.</li><li>For DSL operators, store data is upgraded lazily in the background.</li><li>No upgrade happens if you provide a custom XxxBytesStoreSupplier, but you can opt-in by implementing the <a href=/36/javadoc/org/apache/kafka/streams/state/TimestampedBytesStore.html>TimestampedBytesStore</a> interface. In this case, the old format is retained, and Streams uses a proxy store that removes/adds timestamps on read/write.</li></ul><h1 id=versioned-key-value-state-stores>Versioned Key-Value State Stores<a class=td-heading-self-link href=#versioned-key-value-state-stores aria-label="Heading self-link"></a></h1><p>Versioned key-value state stores are available since Kafka Streams 3.5. Rather than storing a single record version (value and timestamp) per key, versioned state stores may store multiple record versions per key. This allows versioned state stores to support timestamped retrieval operations to return the latest record (per key) as of a specified timestamp.</p><p>You can create a persistent, versioned state store by passing a <a href=/36/javadoc/org/apache/kafka/streams/state/Stores.html#persistentVersionedKeyValueStore%5C(java.lang.String,java.time.Duration%5C)>VersionedBytesStoreSupplier</a> to the <a href=/36/javadoc/org/apache/kafka/streams/state/Stores.html#versionedKeyValueStoreBuilder%5C(java.lang.String,java.time.Duration%5C)>versionedKeyValueStoreBuilder</a>, or by implementing your own <a href=/36/javadoc/org/apache/kafka/streams/state/VersionedKeyValueStore.html>VersionedKeyValueStore</a>.</p><p>Each versioned store has an associated, fixed-duration <em>history retention</em> parameter which specifies long old record versions should be kept for. In particular, a versioned store guarantees to return accurate results for timestamped retrieval operations where the timestamp being queried is within history retention of the current observed stream time.</p><p>History retention also doubles as its <em>grace period</em> , which determines how far back in time out-of-order writes to the store will be accepted. A versioned store will not accept writes (inserts, updates, or deletions) if the timestamp associated with the write is older than the current observed stream time by more than the grace period. Stream time in this context is tracked per-partition, rather than per-key, which means it&rsquo;s important that grace period (i.e., history retention) be set high enough to accommodate a record with one key arriving out-of-order relative to a record for another key.</p><p>Because the memory footprint of versioned key-value stores is higher than that of non-versioned key-value stores, you may want to adjust your <a href=/36/streams/developer-guide/memory-mgmt/#streams-developer-guide-memory-management-rocksdb>RocksDB memory settings</a> accordingly. Benchmarking your application with versioned stores is also advised as performance is expected to be worse than when using non-versioned stores.</p><p>Versioned stores do not support caching or interactive queries at this time. Also, window stores and global tables may not be versioned.</p><p><strong>Upgrade note:</strong> Versioned state stores are opt-in only; no automatic upgrades from non-versioned to versioned stores will take place.</p><p>Upgrades are supported from persistent, non-versioned key-value stores to persistent, versioned key-value stores as long as the original store has the same changelog topic format as the versioned store being upgraded to. Both persistent <a href=/36/javadoc/org/apache/kafka/streams/state/Stores.html#persistentKeyValueStore%5C(java.lang.String%5C)>key-value stores</a> and <a href=/36/javadoc/org/apache/kafka/streams/state/Stores.html#persistentTimestampedKeyValueStore%5C(java.lang.String%5C)>timestamped key-value stores</a> share the same changelog topic format as <a href=/36/javadoc/org/apache/kafka/streams/state/Stores.html#persistentVersionedKeyValueStore%5C(java.lang.String,java.time.Duration%5C)>persistent versioned key-value stores</a>, and therefore both are eligible for upgrades.</p><p>If you wish to upgrade an application using persistent, non-versioned key-value stores to use persistent, versioned key-value stores instead, you can perform the following procedure:</p><ul><li>Stop all application instances, and <a href=/36/streams/developer-guide/app-reset-tool/#streams-developer-guide-reset-local-environment>clear any local state directories</a> for the store(s) being upgraded.</li><li>Update your application code to use versioned stores where desired.</li><li>Update your changelog topic configs, for the relevant state stores, to set the value of <code>min.compaction.lag.ms</code> to be at least your desired history retention. History retention plus one day is recommended as buffer for the use of broker wall clock time during compaction.</li><li>Restart your application instances and allow time for the versioned stores to rebuild state from changelog.</li></ul><h1 id=implementing-custom-state-stores>Implementing Custom State Stores<a class=td-heading-self-link href=#implementing-custom-state-stores aria-label="Heading self-link"></a></h1><p>You can use the built-in state store types or implement your own. The primary interface to implement for the store is <code>org.apache.kafka.streams.processor.StateStore</code>. Kafka Streams also has a few extended interfaces such as <code>KeyValueStore</code> and <code>VersionedKeyValueStore</code>.</p><p>Note that your customized <code>org.apache.kafka.streams.processor.StateStore</code> implementation also needs to provide the logic on how to restore the state via the <code>org.apache.kafka.streams.processor.StateRestoreCallback</code> or <code>org.apache.kafka.streams.processor.BatchingStateRestoreCallback</code> interface. Details on how to instantiate these interfaces can be found in the <a href=/36/javadoc/org/apache/kafka/streams/processor/StateStore.html>javadocs</a>.</p><p>You also need to provide a &ldquo;builder&rdquo; for the store by implementing the <code>org.apache.kafka.streams.state.StoreBuilder</code> interface, which Kafka Streams uses to create instances of your store.</p><h1 id=accessing-processor-context>Accessing Processor Context<a class=td-heading-self-link href=#accessing-processor-context aria-label="Heading self-link"></a></h1><p>As we have mentioned in the Defining a Stream Processor section, a <code>ProcessorContext</code> control the processing workflow, such as scheduling a punctuation function, and committing the current processed state.</p><p>This object can also be used to access the metadata related with the application like <code>applicationId</code>, <code>taskId</code>, and <code>stateDir</code>, and also record related metadata as <code>topic</code>, <code>partition</code>, <code>offset</code>, <code>timestamp</code> and <code>headers</code>.</p><p>Here is an example implementation of how to add a new header to the record:</p><pre><code>public void process(String key, String value) {

    // add a header to the elements
    context().headers().add.(&quot;key&quot;, &quot;value&quot;);
}
</code></pre><h1 id=connecting-processors-and-state-stores>Connecting Processors and State Stores<a class=td-heading-self-link href=#connecting-processors-and-state-stores aria-label="Heading self-link"></a></h1><p>Now that a processor (WordCountProcessor) and the state stores have been defined, you can construct the processor topology by connecting these processors and state stores together by using the <code>Topology</code> instance. In addition, you can add source processors with the specified Kafka topics to generate input data streams into the topology, and sink processors with the specified Kafka topics to generate output data streams out of the topology.</p><p>Here is an example implementation:</p><pre><code>Topology builder = new Topology();
// add the source processor node that takes Kafka topic &quot;source-topic&quot; as input
builder.addSource(&quot;Source&quot;, &quot;source-topic&quot;)
    // add the WordCountProcessor node which takes the source processor as its upstream processor
    .addProcessor(&quot;Process&quot;, () -&gt; new WordCountProcessor(), &quot;Source&quot;)
    // add the count store associated with the WordCountProcessor processor
    .addStateStore(countStoreBuilder, &quot;Process&quot;)
    // add the sink processor node that takes Kafka topic &quot;sink-topic&quot; as output
    // and the WordCountProcessor node as its upstream processor
    .addSink(&quot;Sink&quot;, &quot;sink-topic&quot;, &quot;Process&quot;);
</code></pre><p>Here is a quick explanation of this example:</p><ul><li>A source processor node named <code>"Source"</code> is added to the topology using the <code>addSource</code> method, with one Kafka topic <code>"source-topic"</code> fed to it.</li><li>A processor node named <code>"Process"</code> with the pre-defined <code>WordCountProcessor</code> logic is then added as the downstream processor of the <code>"Source"</code> node using the <code>addProcessor</code> method.</li><li>A predefined persistent key-value state store is created and associated with the <code>"Process"</code> node, using <code>countStoreBuilder</code>.</li><li>A sink processor node is then added to complete the topology using the <code>addSink</code> method, taking the <code>"Process"</code> node as its upstream processor and writing to a separate <code>"sink-topic"</code> Kafka topic (note that users can also use another overloaded variant of <code>addSink</code> to dynamically determine the Kafka topic to write to for each received record from the upstream processor).</li></ul><p>In some cases, it may be more convenient to add and connect a state store at the same time as you add the processor to the topology. This can be done by implementing <code>ConnectedStoreProvider#stores()</code> on the <code>ProcessorSupplier</code> instead of calling <code>Topology#addStateStore()</code>, like this:</p><pre><code>Topology builder = new Topology();
// add the source processor node that takes Kafka &quot;source-topic&quot; as input
builder.addSource(&quot;Source&quot;, &quot;source-topic&quot;)
    // add the WordCountProcessor node which takes the source processor as its upstream processor.
    // the ProcessorSupplier provides the count store associated with the WordCountProcessor
    .addProcessor(&quot;Process&quot;, new ProcessorSupplier&lt;String, String, String, String&gt;() {
        public Processor&lt;String, String, String, String&gt; get() {
            return new WordCountProcessor();
        }

        public Set&lt;StoreBuilder&lt;?&gt;&gt; stores() {
            final StoreBuilder&lt;KeyValueStore&lt;String, Long&gt;&gt; countsStoreBuilder =
                Stores
                    .keyValueStoreBuilder(
                        Stores.persistentKeyValueStore(&quot;Counts&quot;),
                        Serdes.String(),
                        Serdes.Long()
                    );
            return Collections.singleton(countsStoreBuilder);
        }
    }, &quot;Source&quot;)
    // add the sink processor node that takes Kafka topic &quot;sink-topic&quot; as output
    // and the WordCountProcessor node as its upstream processor
    .addSink(&quot;Sink&quot;, &quot;sink-topic&quot;, &quot;Process&quot;);
</code></pre><p>This allows for a processor to &ldquo;own&rdquo; state stores, effectively encapsulating their usage from the user wiring the topology. Multiple processors that share a state store may provide the same store with this technique, as long as the <code>StoreBuilder</code> is the same <code>instance</code>.</p><p>In these topologies, the <code>"Process"</code> stream processor node is considered a downstream processor of the <code>"Source"</code> node, and an upstream processor of the <code>"Sink"</code> node. As a result, whenever the <code>"Source"</code> node forwards a newly fetched record from Kafka to its downstream <code>"Process"</code> node, the <code>WordCountProcessor#process()</code> method is triggered to process the record and update the associated state store. Whenever <code>context#forward()</code> is called in the <code>WordCountProcessor#punctuate()</code> method, the aggregate key-value pair will be sent via the <code>"Sink"</code> processor node to the Kafka topic <code>"sink-topic"</code>. Note that in the <code>WordCountProcessor</code> implementation, you must refer to the same store name <code>"Counts"</code> when accessing the key-value store, otherwise an exception will be thrown at runtime, indicating that the state store cannot be found. If the state store is not associated with the processor in the <code>Topology</code> code, accessing it in the processor&rsquo;s <code>init()</code> method will also throw an exception at runtime, indicating the state store is not accessible from this processor.</p><p>Note that the <code>Topology#addProcessor</code> function takes a <code>ProcessorSupplier</code> as argument, and that the supplier pattern requires that a new <code>Processor</code> instance is returned each time <code>ProcessorSupplier#get()</code> is called. Creating a single <code>Processor</code> object and returning the same object reference in <code>ProcessorSupplier#get()</code> would be a violation of the supplier pattern and leads to runtime exceptions. So remember not to provide a singleton <code>Processor</code> instance to <code>Topology</code>. The <code>ProcessorSupplier</code> should always generate a new instance each time <code>ProcessorSupplier#get()</code> gets called.</p><p>Now that you have fully defined your processor topology in your application, you can proceed to <a href=/36/streams/developer-guide/running-app/#streams-developer-guide-execution>running the Kafka Streams application</a>.</p><p><a href=/36/streams/developer-guide/dsl-api/>Previous</a> <a href=/36/streams/developer-guide/datatypes/>Next</a></p><ul><li><a href=/documentation>Documentation</a></li><li><a href=/streams>Kafka Streams</a></li><li><a href=/streams/developer-guide/>Developer Guide</a></li></ul><style>.feedback--answer{display:inline-block}.feedback--answer-no{margin-left:1em}.feedback--response{display:none;margin-top:1em}.feedback--response__visible{display:block}</style><div class=d-print-none><h2 class=feedback--title>Feedback</h2><p class=feedback--question>Was this page helpful?</p><button class="btn btn-primary mb-4 feedback--answer feedback--answer-yes">Yes</button>
<button class="btn btn-primary mb-4 feedback--answer feedback--answer-no">No</button><p class="feedback--response feedback--response-yes">Glad to hear it! Please <a href=https://github.com/USERNAME/REPOSITORY/issues/new>tell us how we can improve</a>.</p><p class="feedback--response feedback--response-no">Sorry to hear that. Please <a href=https://github.com/USERNAME/REPOSITORY/issues/new>tell us how we can improve</a>.</p></div><script>const yesButton=document.querySelector(".feedback--answer-yes"),noButton=document.querySelector(".feedback--answer-no"),yesResponse=document.querySelector(".feedback--response-yes"),noResponse=document.querySelector(".feedback--response-no"),disableButtons=()=>{yesButton.disabled=!0,noButton.disabled=!0},sendFeedback=e=>{if(typeof gtag!="function")return;gtag("event","page_helpful",{event_category:"Helpful",event_label:window.location.pathname,value:e})};yesButton.addEventListener("click",()=>{yesResponse.classList.add("feedback--response__visible"),disableButtons(),sendFeedback(100)}),noButton.addEventListener("click",()=>{noResponse.classList.add("feedback--response__visible"),disableButtons(),sendFeedback(0)})</script><br><div class=td-page-meta__lastmod>Last modified January 3, 2025: <a href=https://github.com/apache/kafka-site//commit/23a72780f1857dabedac517fd527a3e5e8bfe080>Fixes links for javadocs, dockerfile to use local build (23a72780)</a></div></div></main></div></div><footer class="td-footer row d-print-none"><div class=container-fluid><div class="row mx-md-2"><div class="td-footer__left col-6 col-sm-4 order-sm-1"><ul class=td-footer__links-list><li class=td-footer__links-item data-bs-toggle=tooltip title=Contact aria-label=Contact><a target=_blank rel=noopener href=/community/contact/ aria-label=Contact><i class="fa fa-envelope"></i></a></li><li class=td-footer__links-item data-bs-toggle=tooltip title=Twitter aria-label=Twitter><a target=_blank rel=noopener href=https://twitter.com/apachekafka aria-label=Twitter><i class="fab fa-twitter"></i></a></li><li class=td-footer__links-item data-bs-toggle=tooltip title="Stack Overflow" aria-label="Stack Overflow"><a target=_blank rel=noopener href=https://stackoverflow.com/questions/tagged/apache-kafka aria-label="Stack Overflow"><i class="fab fa-stack-overflow"></i></a></li></ul></div><div class="td-footer__right col-6 col-sm-4 order-sm-3"><ul class=td-footer__links-list><li class=td-footer__links-item data-bs-toggle=tooltip title=GitHub aria-label=GitHub><a target=_blank rel=noopener href=https://github.com/apache/kafka aria-label=GitHub><i class="fab fa-github"></i></a></li><li class=td-footer__links-item data-bs-toggle=tooltip title="Developer mailing list" aria-label="Developer mailing list"><a target=_blank rel=noopener href=mailto:dev@kafka.apache.org aria-label="Developer mailing list"><i class="fa fa-envelope"></i></a></li></ul></div><div class="td-footer__center col-12 col-sm-4 py-2 order-sm-2"><span class=td-footer__copyright>&copy;
2014&ndash;2025
<span class=td-footer__authors>By <a href=https://www.apache.org/>Apache Software Foundation</a> under the terms of the <a href=https://www.apache.org/licenses/LICENSE-2.0>Apache License v2</a></span></span><span class=td-footer__all_rights_reserved>All Rights Reserved</span><span class=ms-2><a href=https://privacy.apache.org/policies/privacy-policy-public.html target=_blank rel=noopener>Privacy Policy</a></span></div></div></div></footer></div><script src=/js/main.min.dc2c0119076a0df855e55a8044ce0de74b7b9033c20e853e22d7ec7e9bdde965.js integrity="sha256-3CwBGQdqDfhV5VqARM4N50t7kDPCDoU+Itfsfpvd6WU=" crossorigin=anonymous></script><script defer src=/js/click-to-copy.min.73478a7d4807698aed7e355eb23f9890ca18fea3158604c8471746d046702bad.js integrity="sha256-c0eKfUgHaYrtfjVesj+YkMoY/qMVhgTIRxdG0EZwK60=" crossorigin=anonymous></script><script src=/js/tabpane-persist.js></script></body></html>
<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Design on</title><link>https://example.kafka-site-md.dev/081/design/</link><description>Recent content in Design on</description><generator>Hugo -- gohugo.io</generator><language>en</language><atom:link href="https://example.kafka-site-md.dev/081/design/index.xml" rel="self" type="application/rss+xml"/><item><title>Design</title><link>https://example.kafka-site-md.dev/081/design/design/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://example.kafka-site-md.dev/081/design/design/</guid><description>Motivation We designed Kafka to be able to act as a unified platform for handling all the real-time data feeds a large company might have. To do this we had to think through a fairly broad set of use cases.
It would have to have high-throughput to support high volume event streams such as real-time log aggregation.
It would need to deal gracefully with large data backlogs to be able to support periodic data loads from offline systems.</description></item></channel></rss>
<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Operations on</title><link>https://example.kafka-site-md.dev/08/operations/</link><description>Recent content in Operations on</description><generator>Hugo -- gohugo.io</generator><language>en</language><atom:link href="https://example.kafka-site-md.dev/08/operations/index.xml" rel="self" type="application/rss+xml"/><item><title>Datacenters</title><link>https://example.kafka-site-md.dev/08/operations/datacenters/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://example.kafka-site-md.dev/08/operations/datacenters/</guid><description>Datacenters Some deployments will need to manage a data pipeline that spans multiple datacenters. Our approach to this is to deploy a local Kafka cluster in each datacenter and machines in each location interact only with their local cluster.
For applications that need a global view of all data we use the mirror maker tool to provide clusters which have aggregate data mirrored from all datacenters. These aggregator clusters are used for reads by applications that require this.</description></item><item><title>Kafka Configuration</title><link>https://example.kafka-site-md.dev/08/operations/kafka-configuration/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://example.kafka-site-md.dev/08/operations/kafka-configuration/</guid><description>Kafka Configuration Kafka 0.8 is the version we currently run. We are currently running with replication but with producers acks = 1.
Important Server Configurations The most important server configurations for performance are those that control the disk flush rate. The more often data is flushed to disk, the more &amp;ldquo;seek-bound&amp;rdquo; Kafka will be and the lower the throughput. However very low application flush rates can lead to high latency when the flush finally does occur (because of the volume of data that must be flushed).</description></item><item><title>Java Version</title><link>https://example.kafka-site-md.dev/08/operations/java-version/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://example.kafka-site-md.dev/08/operations/java-version/</guid><description>Java Version Any version of Java 1.6 or later should work fine, we are using 1.6.0_21. Here are our command line options:
java -server -Xms3072m -Xmx3072m -XX:NewSize=256m -XX:MaxNewSize=256m -XX:+UseParNewGC -XX:+UseConcMarkSweepGC -XX:+UseCMSInitiatingOccupancyOnly -XX:+CMSConcurrentMTEnabled -XX:+CMSScavengeBeforeRemark -XX:CMSInitiatingOccupancyFraction=30 -XX:+PrintGCDetails -XX:+PrintGCDateStamps -XX:+PrintTenuringDistribution -Xloggc:logs/gc.log -Djava.awt.headless=true -Dcom.sun.management.jmxremote -classpath &amp;lt;long list of jars&amp;gt; the.actual.Class</description></item><item><title>Hardware and OS</title><link>https://example.kafka-site-md.dev/08/operations/hardware-and-os/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://example.kafka-site-md.dev/08/operations/hardware-and-os/</guid><description>Hardware and OS We are using dual quad-core Intel Xeon machines with 24GB of memory.
You need sufficient memory to buffer active readers and writers. You can do a back-of-the-envelope estimate of memory needs by assuming you want to be able to buffer for 30 seconds and compute your memory need as write_throughput*30.
The disk throughput is important. We have 8x7200 rpm SATA drives. In general disk throughput is the performance bottleneck, and more disks is more better.</description></item><item><title>Monitoring</title><link>https://example.kafka-site-md.dev/08/operations/monitoring/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://example.kafka-site-md.dev/08/operations/monitoring/</guid><description>Monitoring Kafka uses Yammer Metrics for metrics reporting in both the server and the client. This can be configured to report stats using pluggable stats reporters to hook up to your monitoring system.
The easiest way to see the available metrics to fire up jconsole and point it at a running kafka client or server; this will all browsing all metrics with JMX.
We pay particular we do graphing and alerting on the following metrics: Description Mbean name Normal value Message in rate &amp;ldquo;kafka.</description></item><item><title>Zookeeper</title><link>https://example.kafka-site-md.dev/08/operations/zookeeper/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://example.kafka-site-md.dev/08/operations/zookeeper/</guid><description>Zookeeper Stable version At LinkedIn, we are running Zookeeper 3.3.*. Version 3.3.3 has known serious issues regarding ephemeral node deletion and session expirations. After running into those issues in production, we upgraded to 3.3.4 and have been running that smoothly for over a year now.
Operationalizing Zookeeper Operationally, we do the following for a healthy Zookeeper installation:
Redundancy in the physical/hardware/network layout: try not to put them all in the same rack, decent (but don&amp;rsquo;t go nuts) hardware, try to keep redundant power and network paths, etc</description></item></channel></rss>
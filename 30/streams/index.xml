<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Kafka Streams on</title><link>https://example.kafka-site-md.dev/30/streams/</link><description>Recent content in Kafka Streams on</description><generator>Hugo -- gohugo.io</generator><language>en</language><atom:link href="https://example.kafka-site-md.dev/30/streams/index.xml" rel="self" type="application/rss+xml"/><item><title>Introduction</title><link>https://example.kafka-site-md.dev/30/streams/introduction/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://example.kafka-site-md.dev/30/streams/introduction/</guid><description>Kafka Streams Introduction Run Demo App Tutorial: Write App Concepts Architecture Developer Guide Upgrade
The easiest way to write mission-critical real-time applications and microservices Kafka Streams is a client library for building applications and microservices, where the input and output data are stored in Kafka clusters. It combines the simplicity of writing and deploying standard Java and Scala applications on the client side with the benefits of Kafka&amp;rsquo;s server-side cluster technology.</description></item><item><title>Quick Start</title><link>https://example.kafka-site-md.dev/30/streams/quickstart/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://example.kafka-site-md.dev/30/streams/quickstart/</guid><description>Run Kafka Streams Demo Application Introduction Run Demo App Tutorial: Write App Concepts Architecture Developer Guide Upgrade
This tutorial assumes you are starting fresh and have no existing Kafka or ZooKeeper data. However, if you have already started Kafka and ZooKeeper, feel free to skip the first two steps.
Kafka Streams is a client library for building mission-critical real-time applications and microservices, where the input and/or output data is stored in Kafka clusters.</description></item><item><title>Write a streams app</title><link>https://example.kafka-site-md.dev/30/streams/tutorial/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://example.kafka-site-md.dev/30/streams/tutorial/</guid><description>Tutorial: Write a Kafka Streams Application Introduction Run Demo App Tutorial: Write App Concepts Architecture Developer Guide Upgrade
In this guide we will start from scratch on setting up your own project to write a stream processing application using Kafka Streams. It is highly recommended to read the quickstart first on how to run a Streams application written in Kafka Streams if you have not done so.
Setting up a Maven Project We are going to use a Kafka Streams Maven Archetype for creating a Streams project structure with the following commands:</description></item><item><title>Core Concepts</title><link>https://example.kafka-site-md.dev/30/streams/core-concepts/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://example.kafka-site-md.dev/30/streams/core-concepts/</guid><description>Core Concepts Introduction Run Demo App Tutorial: Write App Concepts Architecture Developer Guide Upgrade
Kafka Streams is a client library for processing and analyzing data stored in Kafka. It builds upon important stream processing concepts such as properly distinguishing between event time and processing time, windowing support, and simple yet efficient management and real-time querying of application state.
Kafka Streams has a low barrier to entry : You can quickly write and run a small-scale proof-of-concept on a single machine; and you only need to run additional instances of your application on multiple machines to scale up to high-volume production workloads.</description></item><item><title>Architecture</title><link>https://example.kafka-site-md.dev/30/streams/architecture/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://example.kafka-site-md.dev/30/streams/architecture/</guid><description>Architecture Introduction Run Demo App Tutorial: Write App Concepts Architecture Developer Guide Upgrade
Kafka Streams simplifies application development by building on the Kafka producer and consumer libraries and leveraging the native capabilities of Kafka to offer data parallelism, distributed coordination, fault tolerance, and operational simplicity. In this section, we describe how Kafka Streams works underneath the covers.
The picture below shows the anatomy of an application that uses the Kafka Streams library.</description></item><item><title>Upgrade Guide</title><link>https://example.kafka-site-md.dev/30/streams/upgrade-guide/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://example.kafka-site-md.dev/30/streams/upgrade-guide/</guid><description>Upgrade Guide and API Changes Introduction Run Demo App Tutorial: Write App Concepts Architecture Developer Guide Upgrade
Upgrading from any older version to 3.0.0 is possible: if upgrading from 2.3 or below, you will need to do two rolling bounces, where during the first rolling bounce phase you set the config upgrade.from=&amp;quot;older version&amp;quot; (possible values are &amp;quot;0.10.0&amp;quot; - &amp;quot;2.3&amp;quot;) and during the second you remove it. This is required to safely upgrade to the new cooperative rebalancing protocol of the embedded consumer.</description></item></channel></rss>